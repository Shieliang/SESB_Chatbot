import streamlit as st
import boto3
import os
from langchain_aws import ChatBedrock, BedrockEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS

# ================= é…ç½®åŒº =================
BUCKET_NAME = 'sagemaker-us-east-1-987762561422' # ä½ çš„æ¡¶å
DOC_PREFIX = 'Documents/'
FORM_PREFIX = 'Forms/'
MODEL_ID = "anthropic.claude-3-5-sonnet-20240620-v1:0"
INDEX_PATH = "./faiss_index_cache"

# ================= é¡µé¢é…ç½® =================
st.set_page_config(page_title="SESB æ™ºèƒ½å®¢æœ", page_icon="âš¡")
# === é¡¶éƒ¨æ ‡é¢˜æ  (å¸¦æ¸…ç©ºæŒ‰é’®) ===
col1, col2 = st.columns([5, 1])
with col1:
    st.title("âš¡ SESB æ™ºèƒ½ä¸šåŠ¡åŠ©æ‰‹")
with col2:
    if st.button("ğŸ—‘ï¸ æ¸…ç©º", key="reset_btn_top", use_container_width=True):
        # 1. é‡ç½® UIï¼šä¿ç•™æ¬¢è¿è¯­
        st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ SESB æ™ºèƒ½å®¢æœã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"}]
        
        # 2. é”€æ¯ AI è®°å¿† (å¼ºåˆ¶é‡ç½®)
        if "qa_chain" in st.session_state:
            del st.session_state["qa_chain"]
        if "memory" in st.session_state:
            del st.session_state["memory"]
        
        # 3. åˆ·æ–°é¡µé¢
        st.rerun()

# ================= èµ„æºåˆå§‹åŒ– (å¸¦ç¼“å­˜) =================
@st.cache_resource
def init_resources():
    s3 = boto3.client('s3')
    
    # è·å–è¡¨æ ¼åˆ—è¡¨
    available_forms = []
    try:
        response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=FORM_PREFIX)
        if 'Contents' in response:
            for obj in response['Contents']:
                fname = os.path.basename(obj['Key'])
                if fname.lower().endswith('.pdf'): available_forms.append(fname)
    except Exception as e: st.error(f"S3 è¿æ¥é”™è¯¯: {e}")
    
    # åŠ è½½å‘é‡åº“
    embeddings = BedrockEmbeddings(model_id="amazon.titan-embed-text-v1")
    if os.path.exists(INDEX_PATH):
        vectorstore = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    else:
        # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œåˆ™ç”Ÿæˆ (Streamlit ä¼šè½¬åœˆåœˆæç¤ºç”¨æˆ·)
        if not os.path.exists('/tmp/docs'): os.makedirs('/tmp/docs')
        all_docs = []
        resp = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=DOC_PREFIX)
        if 'Contents' in resp:
            for obj in resp['Contents']:
                if obj['Key'].endswith('.pdf'):
                    path = f"/tmp/docs/{os.path.basename(obj['Key'])}"
                    s3.download_file(BUCKET_NAME, obj['Key'], path)
                    all_docs.extend(PyPDFLoader(path).load())
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        texts = splitter.split_documents(all_docs)
        vectorstore = FAISS.from_documents(texts, embeddings)
        vectorstore.save_local(INDEX_PATH)
    
    return s3, available_forms, vectorstore

s3, available_forms, vectorstore = init_resources()
forms_str = ", ".join(available_forms) if available_forms else "æ— "

# ================= é“¾æ¡åˆå§‹åŒ– =================
# ä½¿ç”¨ session_state ä¿è¯é“¾æ¡åœ¨å¯¹è¯ä¸­æŒä¹…å­˜åœ¨
if "qa_chain" not in st.session_state:
    llm = ChatBedrock(model_id=MODEL_ID, model_kwargs={"max_tokens": 1000})
    
    memory = ConversationBufferMemory(
        memory_key="chat_history", return_messages=True, input_key="question", output_key="answer"
    )
    
    sesb_template = f"""
    ä½ æ˜¯ä¸€å SESB (Sabah Electricity Sdn Bhd) çš„ä¸“ä¸šå®¢æœã€‚
    ä½ çš„æœåŠ¡èŒƒå›´**ä»…é™äº**ï¼šç”µåŠ›ç”³è¯·ã€è´¦å•æŸ¥è¯¢ã€ç”µè¡¨ç›¸å…³ã€åœç”µæ•…éšœã€æ‰¿åŒ…å•†ä¿¡æ¯åŠ SESB ç›¸å…³æ”¿ç­–ã€‚
    
    <rules>
    1. ã€ä¸šåŠ¡è¾¹ç•Œ - å…³é”®ï¼ã€‘
       - å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸ SESB ç”µåŠ›ä¸šåŠ¡**æ— å…³**ï¼ˆä¾‹å¦‚ï¼šè¯¢é—®æ°´è´¹ã€å¤©æ°”ã€æ”¿æ²»ã€æ•°å­¦é¢˜ã€å…¶ä»–å…¬å¸ä¸šåŠ¡ã€é—²èŠç­‰ï¼‰ï¼š
       - **å¿…é¡»** æ‹’ç»å›ç­”ã€‚
       - æ ‡å‡†å›å¤è¯æœ¯ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘æ˜¯ SESB ç”µåŠ›å®¢æœï¼Œæ— æ³•å›ç­”ä¸ç”µåŠ›æœåŠ¡æ— å…³çš„é—®é¢˜ã€‚è¯·é—®æœ‰ä»€ä¹ˆå…³äºç”µè¡¨æˆ–è´¦å•çš„äº‹å®œæˆ‘å¯ä»¥å¸®æ‚¨å—ï¼Ÿâ€
    
    2. ã€èµ„æ–™æ¥æºã€‘
       - å¿…é¡»åŸºäºã€å‚è€ƒèµ„æ–™ã€‘å›ç­”ã€‚å¦‚æœèµ„æ–™é‡Œæ²¡æœ‰ç­”æ¡ˆï¼Œå°±è¯´â€œç›®å‰çš„èµ„æ–™é‡Œæ²¡æœ‰ç›¸å…³ä¿¡æ¯â€ï¼Œä¸è¦ç¼–é€ ã€‚
    
    3. ã€éšç§ä¾‹å¤–ã€‘
       - èµ„æ–™é‡Œçš„ Contractor (æ‰¿åŒ…å•†) ç”µè¯/åœ°å€æ˜¯å…¬å¼€ä¿¡æ¯ï¼Œ**å¿…é¡»ç›´æ¥æä¾›**ã€‚
    
    4. ã€è¡¨æ ¼ä¸‹è½½ã€‘
       - æ¨èåˆ—è¡¨ï¼š[{forms_str}]ã€‚å‘Šè¯‰ç”¨æˆ·â€œå¯ä»¥ä¸‹è½½ [æ–‡ä»¶å]â€ã€‚
    
    5. ã€èº«ä»½ç•Œé™ã€‘
       - ä½ æ˜¯å®¢æœï¼Œæˆ‘æ˜¯ç”¨æˆ·ã€‚ä¸è¦é‡å¤æˆ‘çš„é—®é¢˜ï¼Œä¸è¦è‡ªè¨€è‡ªè¯­ã€‚
    </rules>
    
    ã€å¯¹è¯å†å²ã€‘ï¼š
    {{chat_history}}
    
    ã€å‚è€ƒèµ„æ–™ã€‘ï¼š
    {{context}}
    
    ç”¨æˆ·é—®é¢˜ï¼š{{question}}
    
    è¯·ç›´æ¥å›ç­”ï¼š
    """
    
    SESB_PROMPT = PromptTemplate(template=sesb_template, input_variables=["context", "question", "chat_history"])
    
    condense_template = """
    ä»»åŠ¡ï¼šå°†åç»­é—®é¢˜æ”¹å†™ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ã€å®Œæ•´çš„é—®é¢˜ã€‚
    <rules>
    1. å¦‚æœç”¨æˆ·é—®â€œæˆ‘è¯´è¿‡ä»€ä¹ˆâ€æˆ–â€œæˆ‘ä½åœ¨å“ªé‡Œâ€ï¼Œè¯·åŠ¡å¿…æŸ¥çœ‹ <chat_history> å¹¶å°†å…·ä½“ä¿¡æ¯è¡¥å……è¿›é—®é¢˜é‡Œã€‚
    2. ä¿æŒè¯­è¨€ä¸ç”¨æˆ·è¾“å…¥ä¸€è‡´ï¼ˆå¦‚æœç”¨æˆ·ç”¨åè¯­ï¼Œå°±ç”¨åè¯­æ”¹å†™ï¼›å¦‚æœç”¨é©¬æ¥è¯­ï¼Œå°±ç”¨é©¬æ¥è¯­ï¼‰ã€‚
    3. ä¸è¦å›ç­”é—®é¢˜ï¼Œåªéœ€è¾“å‡ºæ”¹å†™åçš„é—®é¢˜ã€‚
    </rules>
    èŠå¤©å†å²: {chat_history}
    åç»­è¾“å…¥: {question}
    ç‹¬ç«‹é—®é¢˜:"""
    
    CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(condense_template)

    st.session_state.qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm, retriever=vectorstore.as_retriever(), memory=memory,
        return_source_documents=True, condense_question_prompt=CONDENSE_QUESTION_PROMPT,
        combine_docs_chain_kwargs={"prompt": SESB_PROMPT}
    )

# ================= èŠå¤©ç•Œé¢é€»è¾‘ =================

# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ SESB æ™ºèƒ½å®¢æœã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"}]

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"], unsafe_allow_html=True) # å…è®¸ HTML æ¸²æŸ“ä¸‹è½½æŒ‰é’®

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. è°ƒç”¨ AI
    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨æŸ¥è¯¢ SESB èµ„æ–™åº“..."):
            try:
                res = st.session_state.qa_chain.invoke({"question": prompt})
                answer = res['answer']
                
                # æ£€æŸ¥è¡¨æ ¼å¹¶ç”ŸæˆæŒ‰é’® HTML
                found_forms = list(set([f for f in available_forms if f.replace('.pdf','').replace('.PDF','').lower() in answer.lower()]))
                if found_forms:
                    answer += "<br><br>ğŸ“‚ <b>æ¨èä¸‹è½½ï¼š</b><br>"
                    for fname in found_forms:
                        try:
                            link = s3.generate_presigned_url('get_object', Params={'Bucket': BUCKET_NAME, 'Key': f"{FORM_PREFIX}{fname}"}, ExpiresIn=3600)
                            # ä½¿ç”¨ HTML æ¸²æŸ“æ¼‚äº®çš„æŒ‰é’®
                            answer += f"""<a href="{link}" target="_blank" style="background-color:#0073bb;color:white;padding:5px 10px;text-decoration:none;border-radius:15px;margin:2px;display:inline-block;">â¬‡ï¸ {fname}</a> """
                        except: pass
                
                st.markdown(answer, unsafe_allow_html=True)
                
                # å­˜å…¥å†å²
                st.session_state.messages.append({"role": "assistant", "content": answer})
                
            except Exception as e:
                st.error(f"ç³»ç»Ÿé”™è¯¯: {e}")